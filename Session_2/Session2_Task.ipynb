{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://keras.io/api/datasets/cifar100/\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data(label_mode=\"fine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = [\n",
    "    \"apple\",\n",
    "    \"aquarium_fish\",\n",
    "    \"baby\",\n",
    "    \"bear\",\n",
    "    \"beaver\",\n",
    "    \"bed\",\n",
    "    \"bee\",\n",
    "    \"beetle\",\n",
    "    \"bicycle\",\n",
    "    \"bottle\",\n",
    "    \"bowl\",\n",
    "    \"boy\",\n",
    "    \"bridge\",\n",
    "    \"bus\",\n",
    "    \"butterfly\",\n",
    "    \"camel\",\n",
    "    \"can\",\n",
    "    \"castle\",\n",
    "    \"caterpillar\",\n",
    "    \"cattle\",\n",
    "    \"chair\",\n",
    "    \"chimpanzee\",\n",
    "    \"clock\",\n",
    "    \"cloud\",\n",
    "    \"cockroach\",\n",
    "    \"couch\",\n",
    "    \"crab\",\n",
    "    \"crocodile\",\n",
    "    \"cup\",\n",
    "    \"dinosaur\",\n",
    "    \"dolphin\",\n",
    "    \"elephant\",\n",
    "    \"flatfish\",\n",
    "    \"forest\",\n",
    "    \"fox\",\n",
    "    \"girl\",\n",
    "    \"hamster\",\n",
    "    \"house\",\n",
    "    \"kangaroo\",\n",
    "    \"keyboard\",\n",
    "    \"lamp\",\n",
    "    \"lawn_mower\",\n",
    "    \"leopard\",\n",
    "    \"lion\",\n",
    "    \"lizard\",\n",
    "    \"lobster\",\n",
    "    \"man\",\n",
    "    \"maple_tree\",\n",
    "    \"motorcycle\",\n",
    "    \"mountain\",\n",
    "    \"mouse\",\n",
    "    \"mushroom\",\n",
    "    \"oak_tree\",\n",
    "    \"orange\",\n",
    "    \"orchid\",\n",
    "    \"otter\",\n",
    "    \"palm_tree\",\n",
    "    \"pear\",\n",
    "    \"pickup_truck\",\n",
    "    \"pine_tree\",\n",
    "    \"plain\",\n",
    "    \"plate\",\n",
    "    \"poppy\",\n",
    "    \"porcupine\",\n",
    "    \"possum\",\n",
    "    \"rabbit\",\n",
    "    \"raccoon\",\n",
    "    \"ray\",\n",
    "    \"road\",\n",
    "    \"rocket\",\n",
    "    \"rose\",\n",
    "    \"sea\",\n",
    "    \"seal\",\n",
    "    \"shark\",\n",
    "    \"shrew\",\n",
    "    \"skunk\",\n",
    "    \"skyscraper\",\n",
    "    \"snail\",\n",
    "    \"snake\",\n",
    "    \"spider\",\n",
    "    \"squirrel\",\n",
    "    \"streetcar\",\n",
    "    \"sunflower\",\n",
    "    \"sweet_pepper\",\n",
    "    \"table\",\n",
    "    \"tank\",\n",
    "    \"telephone\",\n",
    "    \"television\",\n",
    "    \"tiger\",\n",
    "    \"tractor\",\n",
    "    \"train\",\n",
    "    \"trout\",\n",
    "    \"tulip\",\n",
    "    \"turtle\",\n",
    "    \"wardrobe\",\n",
    "    \"whale\",\n",
    "    \"willow_tree\",\n",
    "    \"wolf\",\n",
    "    \"woman\",\n",
    "    \"worm\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'leopard'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 1500\n",
    "label[y_train[i][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Arrangment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.append(x_train.reshape((50000,-1)), y_train, axis=1)\n",
    "train, val = train_test_split(data, test_size = 0.2,random_state=43)\n",
    "\n",
    "test = np.append(x_test.reshape((10000,-1)), y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 3073)\n",
      "(10000, 3073)\n",
      "(10000, 3073)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(val.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 3072) (40000,)\n"
     ]
    }
   ],
   "source": [
    "X_train = train[:,:-1]\n",
    "Y_train = train[:, -1]\n",
    "X_val = val[:,:-1]\n",
    "Y_val = val[:, -1]\n",
    "X_test = test[:,:-1]\n",
    "Y_test = test[:, -1]\n",
    "\n",
    "print(X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logisitc Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuarcy: 0.1716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saifa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "clf = LogisticRegression(random_state=0)\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "\n",
    "y_pred = clf.predict(X_val)\n",
    "print(\"validation accuarcy:\",accuracy_score(Y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Really bad accuracy of 17% with Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3072]\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer1 (Dense)              (None, 3000)              9219000   \n",
      "                                                                 \n",
      " layer2 (Dense)              (None, 2500)              7502500   \n",
      "                                                                 \n",
      " layer3 (Dense)              (None, 2000)              5002000   \n",
      "                                                                 \n",
      " layer4 (Dense)              (None, 1000)              2001000   \n",
      "                                                                 \n",
      " layer5 (Dense)              (None, 500)               500500    \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 100)               50100     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,275,100\n",
      "Trainable params: 24,275,100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputShape = [X_train[i,:].shape[0]]\n",
    "print(inputShape)\n",
    "classes_num = 100\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(layers.InputLayer(input_shape = inputShape)) # add first the input shape\n",
    "model.add(layers.Dense(3000, activation=\"relu\", kernel_initializer=tf.keras.initializers.HeNormal(), name=\"layer1\"))\n",
    "model.add(layers.Dense(2500, activation=\"relu\", kernel_initializer=tf.keras.initializers.HeNormal(), name=\"layer2\"))\n",
    "model.add(layers.Dense(2000, activation=\"relu\", kernel_initializer=tf.keras.initializers.HeNormal(), name=\"layer3\"))\n",
    "model.add(layers.Dense(1000, activation=\"relu\", kernel_initializer=tf.keras.initializers.HeNormal(), name=\"layer4\"))\n",
    "model.add(layers.Dense(500, activation=\"relu\", kernel_initializer=tf.keras.initializers.HeNormal(), name=\"layer5\"))\n",
    "model.add(layers.Dense(classes_num, activation=\"softmax\" , kernel_initializer=tf.keras.initializers.HeNormal(), name=\"output_layer\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile( optimizer=keras.optimizers.Adam(learning_rate=0.0001), \n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 2s 28ms/step - loss: 403.4444 - sparse_categorical_accuracy: 0.0099\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, Y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that its completely random, it makes sense that the accuracy is pretty much 1% before any training as there are 100 classes to choose from and its a probability of 1 in a 100 to choose a class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "313/313 [==============================] - 38s 119ms/step - loss: 30.6676 - sparse_categorical_accuracy: 0.0317 - val_loss: 7.3626 - val_sparse_categorical_accuracy: 0.0456\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 37s 120ms/step - loss: 6.0432 - sparse_categorical_accuracy: 0.0554 - val_loss: 5.4345 - val_sparse_categorical_accuracy: 0.0543\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 39s 125ms/step - loss: 4.8162 - sparse_categorical_accuracy: 0.0811 - val_loss: 4.9235 - val_sparse_categorical_accuracy: 0.0719\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 39s 123ms/step - loss: 4.3111 - sparse_categorical_accuracy: 0.1075 - val_loss: 4.4057 - val_sparse_categorical_accuracy: 0.0984\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 38s 121ms/step - loss: 4.0221 - sparse_categorical_accuracy: 0.1350 - val_loss: 4.4139 - val_sparse_categorical_accuracy: 0.0958\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 37s 119ms/step - loss: 3.8348 - sparse_categorical_accuracy: 0.1586 - val_loss: 4.2935 - val_sparse_categorical_accuracy: 0.1096\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 37s 120ms/step - loss: 3.6755 - sparse_categorical_accuracy: 0.1837 - val_loss: 4.1439 - val_sparse_categorical_accuracy: 0.1256\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 37s 118ms/step - loss: 3.5265 - sparse_categorical_accuracy: 0.2041 - val_loss: 4.2445 - val_sparse_categorical_accuracy: 0.1228\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 38s 121ms/step - loss: 3.4024 - sparse_categorical_accuracy: 0.2281 - val_loss: 4.1257 - val_sparse_categorical_accuracy: 0.1355\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 39s 124ms/step - loss: 3.2745 - sparse_categorical_accuracy: 0.2502 - val_loss: 4.1083 - val_sparse_categorical_accuracy: 0.1426\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 37s 118ms/step - loss: 3.1626 - sparse_categorical_accuracy: 0.2682 - val_loss: 4.1927 - val_sparse_categorical_accuracy: 0.1360\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 37s 118ms/step - loss: 3.0728 - sparse_categorical_accuracy: 0.2826 - val_loss: 4.1036 - val_sparse_categorical_accuracy: 0.1477\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 37s 117ms/step - loss: 2.9761 - sparse_categorical_accuracy: 0.2997 - val_loss: 4.0796 - val_sparse_categorical_accuracy: 0.1592\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 37s 120ms/step - loss: 2.8923 - sparse_categorical_accuracy: 0.3144 - val_loss: 4.0840 - val_sparse_categorical_accuracy: 0.1583\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 38s 122ms/step - loss: 2.8092 - sparse_categorical_accuracy: 0.3327 - val_loss: 4.0277 - val_sparse_categorical_accuracy: 0.1633\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 38s 121ms/step - loss: 2.7327 - sparse_categorical_accuracy: 0.3463 - val_loss: 4.1052 - val_sparse_categorical_accuracy: 0.1621\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 38s 121ms/step - loss: 2.6376 - sparse_categorical_accuracy: 0.3629 - val_loss: 4.1093 - val_sparse_categorical_accuracy: 0.1682\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 38s 122ms/step - loss: 2.5607 - sparse_categorical_accuracy: 0.3801 - val_loss: 4.2705 - val_sparse_categorical_accuracy: 0.1611\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 2.5034 - sparse_categorical_accuracy: 0.3918 - val_loss: 4.1611 - val_sparse_categorical_accuracy: 0.1741\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 39s 125ms/step - loss: 2.4091 - sparse_categorical_accuracy: 0.4108 - val_loss: 4.1763 - val_sparse_categorical_accuracy: 0.1750\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 38s 121ms/step - loss: 2.3067 - sparse_categorical_accuracy: 0.4285 - val_loss: 4.1828 - val_sparse_categorical_accuracy: 0.1874\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 38s 123ms/step - loss: 2.2048 - sparse_categorical_accuracy: 0.4534 - val_loss: 4.2952 - val_sparse_categorical_accuracy: 0.1862\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 39s 125ms/step - loss: 2.0959 - sparse_categorical_accuracy: 0.4751 - val_loss: 4.3390 - val_sparse_categorical_accuracy: 0.1914\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 2.0111 - sparse_categorical_accuracy: 0.4960 - val_loss: 4.3669 - val_sparse_categorical_accuracy: 0.1891\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 1.9076 - sparse_categorical_accuracy: 0.5145 - val_loss: 4.4011 - val_sparse_categorical_accuracy: 0.1909\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 40s 129ms/step - loss: 1.8156 - sparse_categorical_accuracy: 0.5386 - val_loss: 4.5243 - val_sparse_categorical_accuracy: 0.1910\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 1.7091 - sparse_categorical_accuracy: 0.5640 - val_loss: 4.4795 - val_sparse_categorical_accuracy: 0.1985\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 1.5912 - sparse_categorical_accuracy: 0.5889 - val_loss: 4.6994 - val_sparse_categorical_accuracy: 0.2010\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 1.4704 - sparse_categorical_accuracy: 0.6166 - val_loss: 4.8059 - val_sparse_categorical_accuracy: 0.2057\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 1.3558 - sparse_categorical_accuracy: 0.6454 - val_loss: 4.9441 - val_sparse_categorical_accuracy: 0.2104\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 1.2602 - sparse_categorical_accuracy: 0.6673 - val_loss: 5.0706 - val_sparse_categorical_accuracy: 0.2019\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 41s 131ms/step - loss: 1.1652 - sparse_categorical_accuracy: 0.6910 - val_loss: 5.0946 - val_sparse_categorical_accuracy: 0.2080\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 1.0433 - sparse_categorical_accuracy: 0.7218 - val_loss: 5.2759 - val_sparse_categorical_accuracy: 0.2120\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 42s 134ms/step - loss: 0.9986 - sparse_categorical_accuracy: 0.7322 - val_loss: 5.4158 - val_sparse_categorical_accuracy: 0.2092\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.9144 - sparse_categorical_accuracy: 0.7520 - val_loss: 5.5746 - val_sparse_categorical_accuracy: 0.2121\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 42s 135ms/step - loss: 0.8226 - sparse_categorical_accuracy: 0.7774 - val_loss: 5.7705 - val_sparse_categorical_accuracy: 0.2150\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.7874 - sparse_categorical_accuracy: 0.7839 - val_loss: 5.9051 - val_sparse_categorical_accuracy: 0.2122\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.7335 - sparse_categorical_accuracy: 0.7988 - val_loss: 5.9582 - val_sparse_categorical_accuracy: 0.2103\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.6254 - sparse_categorical_accuracy: 0.8294 - val_loss: 6.1168 - val_sparse_categorical_accuracy: 0.2129\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.6363 - sparse_categorical_accuracy: 0.8238 - val_loss: 6.3263 - val_sparse_categorical_accuracy: 0.2097\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 38s 120ms/step - loss: 0.5638 - sparse_categorical_accuracy: 0.8426 - val_loss: 6.2165 - val_sparse_categorical_accuracy: 0.2144\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 39s 126ms/step - loss: 0.5186 - sparse_categorical_accuracy: 0.8536 - val_loss: 6.6781 - val_sparse_categorical_accuracy: 0.2159\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 39s 126ms/step - loss: 0.5235 - sparse_categorical_accuracy: 0.8538 - val_loss: 6.6716 - val_sparse_categorical_accuracy: 0.2059\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.4973 - sparse_categorical_accuracy: 0.8597 - val_loss: 6.7775 - val_sparse_categorical_accuracy: 0.2182\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 40s 126ms/step - loss: 0.3958 - sparse_categorical_accuracy: 0.8888 - val_loss: 7.2350 - val_sparse_categorical_accuracy: 0.2197\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 42s 133ms/step - loss: 0.4021 - sparse_categorical_accuracy: 0.8854 - val_loss: 7.0636 - val_sparse_categorical_accuracy: 0.2210\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 41s 130ms/step - loss: 0.4203 - sparse_categorical_accuracy: 0.8810 - val_loss: 7.1583 - val_sparse_categorical_accuracy: 0.2113\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 40s 126ms/step - loss: 0.3804 - sparse_categorical_accuracy: 0.8903 - val_loss: 7.4642 - val_sparse_categorical_accuracy: 0.2185\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 40s 128ms/step - loss: 0.3756 - sparse_categorical_accuracy: 0.8942 - val_loss: 7.4345 - val_sparse_categorical_accuracy: 0.2208\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 47s 151ms/step - loss: 0.3389 - sparse_categorical_accuracy: 0.9035 - val_loss: 7.4701 - val_sparse_categorical_accuracy: 0.2230\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    epochs=50,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_val, Y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "As you can see my model's accuracy has reached 90% on training and 22% on validation, that's definitely an improvement over 1% with logisitic regression however it is really bad still. There seems to be a lot overfitting happening too as the model was trained well on the trianing data however didnt predict much of the validation. Next step is finding out how we can optimize our model for better results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our input shape (32, 32, 3)\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_18 (Conv2D)          (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 15, 15, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 6, 6, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 2, 2, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 100)               12900     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 270,372\n",
      "Trainable params: 270,372\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputShape=(32,32,3)\n",
    "print(\"our input shape\",inputShape)\n",
    "#here we can see that CNN take the input as 3D tensors not a flatten 1D tensor\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=inputShape))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(100, activation='softmax'))\n",
    "\n",
    "# Checking the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[:,:-1].reshape(-1, 32, 32, 3)\n",
    "X_train.shape\n",
    "X_val = val[:,:-1].reshape(-1, 32, 32, 3)\n",
    "# Y_val = val[:, -1].reshape(-1, 32, 32, 3)\n",
    "X_test = test[:,:-1].reshape(-1, 32, 32, 3)\n",
    "# Y_test = test[:, -1].reshape(-1, 32, 32, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),  # Optimizer\n",
    "    # Loss function to minimize\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    # List of metrics to monitor\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "Epoch 1/20\n",
      "313/313 [==============================] - 138s 439ms/step - loss: 1.5636 - sparse_categorical_accuracy: 0.5555 - val_loss: 1.5149 - val_sparse_categorical_accuracy: 0.5711\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 136s 434ms/step - loss: 1.5508 - sparse_categorical_accuracy: 0.5610 - val_loss: 1.5339 - val_sparse_categorical_accuracy: 0.5704\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 132s 420ms/step - loss: 1.5506 - sparse_categorical_accuracy: 0.5561 - val_loss: 1.5661 - val_sparse_categorical_accuracy: 0.5639\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 132s 423ms/step - loss: 1.5361 - sparse_categorical_accuracy: 0.5646 - val_loss: 1.5097 - val_sparse_categorical_accuracy: 0.5761\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 130s 416ms/step - loss: 1.5288 - sparse_categorical_accuracy: 0.5652 - val_loss: 1.5869 - val_sparse_categorical_accuracy: 0.5608\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 130s 416ms/step - loss: 1.5111 - sparse_categorical_accuracy: 0.5694 - val_loss: 1.5195 - val_sparse_categorical_accuracy: 0.5726\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 130s 417ms/step - loss: 1.5065 - sparse_categorical_accuracy: 0.5688 - val_loss: 1.4932 - val_sparse_categorical_accuracy: 0.5821\n",
      "Epoch 8/20\n",
      "313/313 [==============================] - 139s 445ms/step - loss: 1.5013 - sparse_categorical_accuracy: 0.5727 - val_loss: 1.5002 - val_sparse_categorical_accuracy: 0.5804\n",
      "Epoch 9/20\n",
      "313/313 [==============================] - 147s 469ms/step - loss: 1.4977 - sparse_categorical_accuracy: 0.5728 - val_loss: 1.5097 - val_sparse_categorical_accuracy: 0.5770\n",
      "Epoch 10/20\n",
      "313/313 [==============================] - 135s 431ms/step - loss: 1.4887 - sparse_categorical_accuracy: 0.5720 - val_loss: 1.4918 - val_sparse_categorical_accuracy: 0.5833\n",
      "Epoch 11/20\n",
      "313/313 [==============================] - 136s 435ms/step - loss: 1.4881 - sparse_categorical_accuracy: 0.5764 - val_loss: 1.5321 - val_sparse_categorical_accuracy: 0.5757\n",
      "Epoch 12/20\n",
      "313/313 [==============================] - 136s 435ms/step - loss: 1.4780 - sparse_categorical_accuracy: 0.5781 - val_loss: 1.4941 - val_sparse_categorical_accuracy: 0.5807\n",
      "Epoch 13/20\n",
      "313/313 [==============================] - 134s 429ms/step - loss: 1.4710 - sparse_categorical_accuracy: 0.5803 - val_loss: 1.4949 - val_sparse_categorical_accuracy: 0.5847\n",
      "Epoch 14/20\n",
      "313/313 [==============================] - 131s 419ms/step - loss: 1.4711 - sparse_categorical_accuracy: 0.5795 - val_loss: 1.5116 - val_sparse_categorical_accuracy: 0.5823\n",
      "Epoch 15/20\n",
      "313/313 [==============================] - 131s 418ms/step - loss: 1.4602 - sparse_categorical_accuracy: 0.5798 - val_loss: 1.4960 - val_sparse_categorical_accuracy: 0.5869\n",
      "Epoch 16/20\n",
      "313/313 [==============================] - 131s 417ms/step - loss: 1.4534 - sparse_categorical_accuracy: 0.5821 - val_loss: 1.5256 - val_sparse_categorical_accuracy: 0.5759\n",
      "Epoch 17/20\n",
      "313/313 [==============================] - 130s 417ms/step - loss: 1.4465 - sparse_categorical_accuracy: 0.5836 - val_loss: 1.5175 - val_sparse_categorical_accuracy: 0.5777\n",
      "Epoch 18/20\n",
      "313/313 [==============================] - 130s 417ms/step - loss: 1.4374 - sparse_categorical_accuracy: 0.5864 - val_loss: 1.5281 - val_sparse_categorical_accuracy: 0.5752\n",
      "Epoch 19/20\n",
      "313/313 [==============================] - 130s 417ms/step - loss: 1.4339 - sparse_categorical_accuracy: 0.5883 - val_loss: 1.5599 - val_sparse_categorical_accuracy: 0.5713\n",
      "Epoch 20/20\n",
      "313/313 [==============================] - 130s 416ms/step - loss: 1.4307 - sparse_categorical_accuracy: 0.5875 - val_loss: 1.4726 - val_sparse_categorical_accuracy: 0.5916\n"
     ]
    }
   ],
   "source": [
    "print(\"Fit model on training data\")\n",
    "history = cnn_model.fit(\n",
    "    X_train, Y_train,\n",
    "    batch_size=128,\n",
    "    epochs=20,\n",
    "    validation_data=(X_val, Y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "My model is a little better with 59% accuracy having used a better model I found here \n",
    "\n",
    "https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-build-a-convnet-for-cifar-10-and-cifar-100-classification-with-keras.md \n",
    "\n",
    "that seems to be implementing a CNN however 59% is still not great but we're getting somewhere. I just need to understand these additional layers more as right now Im really confused about what these layers mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading in an already trained model and setting `trainable=False` so to 'freeze' everything except the last layer which we will add next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "model = tf.keras.Sequential([\n",
    "    hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\", output_shape=[1280],\n",
    "                   trainable=False)\n",
    "])\n",
    "model.build([None, 224, 224, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the last layer to help with the output we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer_18 (KerasLayer)  (None, 1280)             2257984   \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 100)               128100    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,386,084\n",
      "Trainable params: 128,100\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.Dense(classes_num, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile( optimizer=keras.optimizers.Adam(learning_rate=0.0001), \n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This does not work\n",
    "#### I understood how transfer learning works in theory however I cant get it to work here as the model is trained on 224x224 pixel images while my images are 32x32 so I wasn't really sure what to do at this point, I thought about resizing but it'll cause my images to lose a ton of quality. I deduced that Ill have to find a model which is already trained on 32x32 images but I couldnt find it/didnt know where to look."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\n",
    "\n",
    "https://keras.io/guides/transfer_learning/\n",
    "\n",
    "https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-build-a-convnet-for-cifar-10-and-cifar-100-classification-with-keras.md\n",
    "\n",
    "https://www.youtube.com/watch?v=LsdxvjLWkIY&ab_channel=codebasics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
