{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is already split for us so we wont need to use the train_test_split function but we'll need to seperate features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data from .mat files using the loadmat function\n",
    "train_data = loadmat(\"./task 1 data/train.mat\")\n",
    "val_data = loadmat(\"./task 1 data/val.mat\")\n",
    "test_data = loadmat(\"./task 1 data/test.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperating features and labels\n",
    "train_X = train_data['features']\n",
    "train_Y = train_data[\"label\"].flatten()\n",
    "\n",
    "val_X = val_data['features']\n",
    "val_Y = val_data[\"label\"].flatten()\n",
    "\n",
    "test_X = test_data['features']\n",
    "test_Y = test_data[\"label\"].flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtree = DecisionTreeClassifier(max_depth=15, random_state=43)\n",
    "dtree = dtree.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.825\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "pred = dtree.predict(val_X)\n",
    "print(f'Validation accuracy: {accuracy_score(val_Y, pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8138888888888889\n"
     ]
    }
   ],
   "source": [
    "pred = dtree.predict(test_X)\n",
    "print(f'Test accuracy: {accuracy_score(test_Y, pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "The Highest Accuracy I'm able to get is 82.5% on validation and 81.4% on test which is not great but not bad. The max depth of 15 yielded this accuracy. A higher number didn't change the accuracy while a lower depth caused a my accuracy to decrease so I stuck with 15. \n",
    "\n",
    "However we need an accuracy of 95% so we'll check other models.\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(1)\n",
    "knn = knn.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.9888888888888889\n"
     ]
    }
   ],
   "source": [
    "pred = knn.predict(val_X)\n",
    "print(f'Validation accuracy: {accuracy_score(val_Y, pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "pred = knn.predict(test_X)\n",
    "print(f'Test accuracy: {accuracy_score(test_Y, pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "The Highest Accuracy I'm able to get is 98.9% on validation and 97.8% on test which is extremely good. I found that increasing the number of neighbors decreased my accuracy, though not by alot, so 1 neighbor worked perfectly with no overfitting for this data however overfitting might be seen when a larger data set is tested so it might be wise to increase the number of neighbors a little.\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "reg = LogisticRegression(solver='lbfgs', max_iter=1500, random_state=43)\n",
    "reg = reg.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "pred = reg.predict(val_X)\n",
    "print(f'Validation accuracy: {accuracy_score(val_Y, pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.9638888888888889\n"
     ]
    }
   ],
   "source": [
    "pred = reg.predict(test_X)\n",
    "print(f'Validation accuracy: {accuracy_score(test_Y, pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "The Highest Accuracy I'm able to get is 96.7% on validation and 96.4% on test which is also extremely good. Using a different solver such as 'liblinear' allowed me to decrease the max_iter parameter however it also decreased the accuracy so I used a higher max_iter with the defualt solver, 'lbfgs'.\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best to Worst (95% accuracy threshold)\n",
    "1. KNN\n",
    "2. Logistic Regression\n",
    "3. Decision Tree"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "0ddf4247cef8afccad01f9ce1f0d31c2a36367779044d69369aa4d1b2bb49097"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
